import json
import os

import cv2
import numpy as np
import torch
from torch.utils.data import Dataset


class Phoenix(Dataset):
    def __init__(self, path, mode, transforms=None):
        super(Phoenix, self).__init__()
        self.path = path
        self.transforms = transforms

        self.input_images = sorted(os.listdir(f'{path}/rgb'))
        self.seg_images = sorted(os.listdir(f'{path}/semseg_color'))

    def __getitem__(self, idx):
        img = cv2.imread(f'{self.path}/rgb/{self.input_images[idx]}')
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        seg_img = cv2.imread(f'{self.path}/semseg_color/{self.seg_images[idx]}', cv2.IMREAD_UNCHANGED)
        trans_mask = seg_img[:,:,3] == 0
        seg_img[trans_mask] = [255, 255, 255, 255]
        seg_img = cv2.cvtColor(seg_img, cv2.COLOR_BGRA2BGR)

        sample = {
            'img': img,
            'segLabel': seg_img,
            'exist': None,
            'img_name': f'{self.path}/rgb/{self.input_images[idx]}'
        }

        if self.transforms is not None:
            sample = self.transforms(sample)

        W = sample['segLabel'].shape[0]
        H = sample['segLabel'].shape[1]
        segMap = torch.zeros((W,H), dtype=torch.long)

        for ix, color in enumerate(all_classes):
            r = torch.prod((sample['segLabel'][:,:] == torch.tensor(color)).long(), dim=2)*ix
            segMap[:,:] += r
        
        sample['segLabel'] = segMap

        exist = torch.zeros(len(all_classes), dtype=torch.float)
        for ix in range(len(all_classes)):
            #print(ix, (segMap == ix).any().long())
            exist[ix] = (segMap == ix).any().float()
        sample['exist'] = exist

        return sample

    def __len__(self):
        return min(len(self.input_images), len(self.seg_images))

    @staticmethod
    def collate(batch):
        if isinstance(batch[0]['img'], torch.Tensor):
            img = torch.stack([b['img'] for b in batch])
        else:
            img = [b['img'] for b in batch]

        if batch[0]['segLabel'] is None:
            segLabel = None
            exist = None
        elif isinstance(batch[0]['segLabel'], torch.Tensor):
            segLabel = torch.stack([b['segLabel'] for b in batch])
            exist = torch.stack([b['exist'] for b in batch])
        else:
            segLabel = [b['segLabel'] for b in batch]
            exist = [b['exist'] for b in batch]

        samples = {'img': img,
                   'segLabel': segLabel,
                   'exist': exist,
                   'img_name': [x['img_name'] for x in batch]}

        return samples

LANE_MARKING_SEGMENTATION_COLOR = (128, 0, 0)
BLOCKED_AREA_SEGMENTATION_COLOR = (0, 128, 0)
# pedestrian island currently not segmented, could do in the future
# PEDESTRIAN_ISLAND_COLOR = (0, 0, 128)
DRIVABLE_AREA_SEGMENTATION_COLOR = (0, 255, 0)
STOPLINE_SEGMENTATION_COLOR = (0, 255, 255)
STOPLINE_DASHED_SEGMENTATION_COLOR = (255, 255, 0)
ZEBRA_COLOR = (128, 128, 0)
BACKGROUND_COLOR = (0, 0, 0)
EGO_VEHICLE_COLOR = (100, 100, 100)
OBSTACLE_COLOR = (0, 0, 255)
RAMP_COLOR = (0, 100, 0)

# generated by :
# TRAFFIC_MARKING_SEGMENTATION_COLORS = {marking: (255 - 8 * i, 8 * i, 8 * i) for i, marking in
#                                        enumerate(ROADMARKING_TYPE_TO_VISUAL.keys())}
TRAFFIC_MARKING_SEGMENTATION_COLORS = \
    {'10_zone_beginn': (255, 0, 0),
     '20_zone_beginn': (247, 8, 8),
     'stvo-274.1': (239, 16, 16),
     '40_zone_beginn': (231, 24, 24),
     '50_zone_beginn': (223, 32, 32),
     '60_zone_beginn': (215, 40, 40),
     '70_zone_beginn': (207, 48, 48),
     '80_zone_beginn': (199, 56, 56),
     '90_zone_beginn': (191, 64, 64),
     'ende_10_zone': (183, 72, 72),
     'ende_20_zone': (175, 80, 80),
     'stvo-274.2': (167, 88, 88),
     'ende_40_zone': (159, 96, 96),
     'ende_50_zone': (151, 104, 104),
     'ende_60_zone': (143, 112, 112),
     'ende_70_zone': (135, 120, 120),
     'ende_80_zone': (127, 128, 128),
     'ende_90_zone': (119, 136, 136),
     'turn_left': (111, 144, 144),
     'turn_right': (103, 152, 152)}

SIGN_BASE_COLOR = (200, 100, 0)

# generated by
# SIGN_TO_COLOR = {marking: (7 * i, 255 - 7 * i, 7 * i) for i, marking in
#                  enumerate(SIGN_MESHES.keys())}
SIGN_TO_COLOR = {'10_zone_beginn': (0, 255, 0),
 '20_zone_beginn': (7, 248, 7),
 '40_zone_beginn': (14, 241, 14),
 '50_zone_beginn': (21, 234, 21),
 '60_zone_beginn': (28, 227, 28),
 '70_zone_beginn': (35, 220, 35),
 '80_zone_beginn': (42, 213, 42),
 '90_zone_beginn': (49, 206, 49),
 'ende_10_zone': (56, 199, 56),
 'ende_20_zone': (63, 192, 63),
 'ende_40_zone': (70, 185, 70),
 'ende_50_zone': (77, 178, 77),
 'ende_60_zone': (84, 171, 84),
 'ende_70_zone': (91, 164, 91),
 'ende_80_zone': (98, 157, 98),
 'ende_90_zone': (105, 150, 105),
 'stvo-108-10': (112, 143, 112),
 'stvo-110-10': (119, 136, 119),
 'stvo-205': (126, 129, 126),
 'stvo-206': (133, 122, 133),
 'stvo-208': (140, 115, 140),
 'stvo-209-10': (147, 108, 147),
 'stvo-209-20': (154, 101, 154),
 'stvo-222': (161, 94, 161),
 'stvo-274.1': (168, 87, 168),
 'stvo-274.2': (175, 80, 175),
 'stvo-306': (182, 73, 182),
 'stvo-350-10': (189, 66, 189),
 'stvo-625-10': (196, 59, 196),
 'stvo-625-11': (203, 52, 203),
 'stvo-625-20': (210, 45, 210),
 'stvo-625-21': (217, 38, 217)}

INTERSECTION_COLOR = (64, 128, 255)

def convert_to_one_range(color):
    return (color[0]/255, color[1]/255, color[2]/255)

all_classes = [
    LANE_MARKING_SEGMENTATION_COLOR,
    BLOCKED_AREA_SEGMENTATION_COLOR,
    DRIVABLE_AREA_SEGMENTATION_COLOR,
    STOPLINE_SEGMENTATION_COLOR,
    STOPLINE_DASHED_SEGMENTATION_COLOR,
    ZEBRA_COLOR,
    BACKGROUND_COLOR,
    EGO_VEHICLE_COLOR,
    OBSTACLE_COLOR,
    RAMP_COLOR
]

all_classes.extend(TRAFFIC_MARKING_SEGMENTATION_COLORS.values())
all_classes.append(SIGN_BASE_COLOR)
all_classes.extend(SIGN_TO_COLOR.values())
all_classes.append(INTERSECTION_COLOR)

print(len(all_classes))
